\section{Introduction}
\label{sec: introduction}

In the modern era of cloud computing and real-time global services, geo-distributed databases have become essential to many critical large-scale applications \cite{corbett2013spanner, bronson2013tao}. These systems replicate and partition data across multiple geographical regions to provide high durability and significantly improve the latency by storing the data closer to the users. However, this distributed infrastructure comes with several tradeoffs. Given the high communication delays between different servers, it becomes increasingly challenging to synchronize transactions that access data scattered across multiple regions \cite{bailis2013highly}.

Several systems, including Calvin, SLOG, Detock, and Janus, have been proposed to improve transaction throughput and latency in geo-distributed environments \cite{thomson2012calvin, ren2019slog, nguyen2023detock, mu2016consolidating}. Detock, for instance, introduces a novel graph-based deterministic deadlock resolution protocol that allows the system to efficiently process multi-region transactions. Despite these innovations, public performance evaluations of these systems are still limited, especially under complex workloads and diverse scenarios. Most existing studies, including those presented in the original system papers, rely on standard workloads such as TPC-C and YCSB+T, which are known to have a limited scope compared to industry benchmarks \cite{leutenegger1993modeling, tozun2013analyzing, dey2014ycsb+}. TPC-C is highly partitionable, with most transactions accessing only a single partition, which limits the ability to stress the inter-region communication and coordination overhead. YCSB+T, while extending the original YCSB workload to include multi-key transactions, keeps a simplistic key-value data model and lacks important features such as foreign keys, join operations, and relational constraints.

To address these limitations, researchers have turned to more complex workloads such as Product-Parts-Supplier (PPS). Harding et al.\cite{harding2017evaluation} demonstrated that PPS can uncover performance bottlenecks and communication inefficiencies that workloads like TPC-C and YCSB+T miss. However, PPS has typically been used under a narrow set of configurations, making it difficult to fully understand the system behavior under different conditions.

This paper aims to address the lack of comprehensive evaluations by investigating \textit{how modern database systems perform under the PPS workload in geo-distributed settings, and how workload characteristics and environmental factors influence throughput, latency, abort rates, network utilization, and operational cost}.

The main contribution of this work is a configurable benchmarking framework based on the PPS workload and designed to evaluate geo-distributed databases under a variety of realistic scenarios. In addition, we provide a comparative evaluation of several representative systems. The findings aim to inform about the practical performance limits and the potential bottlenecks of these systems and motivate the need for more comprehensive benchmarks.

The remainder of this paper proceeds as follows. Section~\ref{sec: background} starts by introducing the background for this work, including the important characteristics of the evaluated databases and a formal description of the PPS workload. Then, Section~\ref{sec: benchmark-implementation} describes the implementation of the benchmarking framework, and Section~\ref{sec: experimental-setup-and-results} presents the experimental setup together with the raw results. Afterward, in Section~\ref{sec: responsible-research} we discuss the steps taken to ensure the reproducibility of our experiments, and in Section~\ref{sec: discussion} we analyze the results across various scenarios. Finally, Section~\ref{sec: conclusion-and-future-work} concludes with the key findings, summarizes the contributions of this work, and outlines potential directions for future research.